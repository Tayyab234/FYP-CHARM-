# FYP-CHARM-
 CHARM â€“ Chicken Health Assessment through Real-time Monitoring
ğŸ” Project Overview
The CHARM project is a deep learning-based poultry health monitoring system designed to detect, track, and classify diseases in chickens using computer vision. This Jupyter Notebook demonstrates the core functionality of the CHARM pipeline, which integrates object detection, tracking, and multithreaded disease classification using multiple neural network models.

The system uses:

YOLOv11 Models for full-body and neck-region detection.

BoT-SORT Algorithm for multi-object tracking to maintain chicken identities across frames.

ResNet50 Classifiers for both general and specific disease categorization.

Multithreading to process detections and classifications concurrently, enabling real-time performance.

The notebook processes videos/images to detect chickens, track their movement, classify health status, and output annotated media with color-coded bounding boxes (green for healthy, orange for Marekâ€™s, red for other diseases). The system is optimized for real poultry farm conditions, handling clutter, variable lighting, and occlusions.

ğŸ“‚ Files Included
FYP(CHARM).ipynb: The main Jupyter Notebook containing the detection, tracking, and classification code.

Pre-trained YOLOv11 models for full-body and neck detection.

Pre-trained ResNet50 models for full-body and neck-based classification.

Supporting utility functions for quality assessment, threading, and visualization.

ğŸš€ Key Features
ğŸ” Full-body and neck detection using YOLOv11

ğŸ”„ Multi-object tracking with BoT-SORT

ğŸ©º Real-time disease classification (general and specific)

ğŸ¯ Quality-based reclassification to improve accuracy

ğŸŒ Scalable design suitable for real-time web or local deployment
## ğŸ“Š Results

- Full-body detection precision: 96.5%
- Recall: 89.7%
- mAP@50: 95.6%
- neck detection precision : 97%
- General disease classification training accuracy: 97.82%
- General disease classification validation accuracy: 88.41%
- Specific disease classification training accuracy: 99.52%
- Specific disease classification validation accuracy: 91.76%

Videos and additional samples can be found in the [results folder](results/).

ğŸ› ï¸ Technologies Used
. Python

. OpenCV

. PyTorch

. YOLOv8

. ResNet50

. BoT-SORT Tracking

. Jupyter Notebook

â–¶ï¸ How to Run
Clone the repository or download the notebook.

Ensure the following dependencies are installed:

bash
pip install opencv-python torch torchvision yolov5
Place the required pre-trained models in the designated paths inside the notebook.

Run the notebook cell by cell, following the order.

Upload a video or use the webcam to process real-time detection and classification.
